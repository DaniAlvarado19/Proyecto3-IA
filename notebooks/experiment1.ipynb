{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Dispositivo actual: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/experiment1.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Agrega el directorio src al path de Python\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from src.models import (\n",
    "    UNetAutoencoder, ButterflyClassifier, LitAutoencoder,\n",
    "    LitClassifier, create_encoder_classifier\n",
    ")\n",
    "from src.data import ButterflyDataModule\n",
    "from src.utils import (\n",
    "    set_seed, evaluate_model_performance, compare_model_versions,\n",
    "    save_experiment_results, log_batch_predictions\n",
    ")\n",
    "\n",
    "# Configuración inicial\n",
    "DATASET_PATH = Path('Butterfly-dataset')\n",
    "CONFIG_PATH = Path('conf/config.yaml')\n",
    "\n",
    "# Carga la configuración de Hydra\n",
    "config = OmegaConf.load(CONFIG_PATH)\n",
    "\n",
    "# Configuración de dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Establece semilla para reproducibilidad\n",
    "set_seed(config.seed)\n",
    "\n",
    "def train_experiment(unlabeled_ratio: float = 0.7) -> dict:\n",
    "    \"\"\"Ejecuta el experimento completo.\"\"\"\n",
    "    \n",
    "    # Inicializa wandb\n",
    "    experiment_name = f\"exp1_{int(unlabeled_ratio*100)}\"\n",
    "    wandb.init(\n",
    "        project=config.wandb.project,\n",
    "        name=experiment_name,\n",
    "        config=OmegaConf.to_container(config, resolve=True)\n",
    "    )\n",
    "    \n",
    "    # Inicializa el módulo de datos\n",
    "    data_module = ButterflyDataModule(\n",
    "        data_dir=str(DATASET_PATH),\n",
    "        batch_size=config.data.batch_size,\n",
    "        unlabeled_ratio=unlabeled_ratio,\n",
    "        image_size=config.data.image_size,\n",
    "        num_workers=config.data.num_workers\n",
    "    )\n",
    "    data_module.setup()\n",
    "    \n",
    "    # Entrenamiento del autoencoder\n",
    "    print(\"\\nEntrenando Autoencoder...\")\n",
    "    autoencoder = UNetAutoencoder(\n",
    "        in_channels=3,\n",
    "        latent_dim=config.model.autoencoder.latent_dim\n",
    "    )\n",
    "    lit_autoencoder = LitAutoencoder(\n",
    "        autoencoder=autoencoder,\n",
    "        learning_rate=config.training.learning_rate\n",
    "    )\n",
    "    \n",
    "    # Callbacks para el autoencoder\n",
    "    ae_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='train_loss',\n",
    "            patience=config.training.early_stopping_patience,\n",
    "            mode='min'\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            dirpath='checkpoints',\n",
    "            filename=f'{experiment_name}_autoencoder_best',\n",
    "            monitor='train_loss',\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Entrenador para el autoencoder\n",
    "    trainer_ae = L.Trainer(\n",
    "        max_epochs=config.training.max_epochs,\n",
    "        callbacks=ae_callbacks,\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    # Entrenamiento del autoencoder\n",
    "    trainer_ae.fit(lit_autoencoder, data_module.unlabeled_dataloader())\n",
    "    \n",
    "    # Entrenamiento de clasificadores\n",
    "    results = {}\n",
    "    \n",
    "    # Clasificador A (desde cero)\n",
    "    print(\"\\nEntrenando Clasificador A (desde cero)...\")\n",
    "    classifier_a = ButterflyClassifier(num_classes=data_module.num_classes)\n",
    "    lit_classifier_a = LitClassifier(\n",
    "        classifier=classifier_a,\n",
    "        learning_rate=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "        class_weights=data_module.class_weights\n",
    "    )\n",
    "    \n",
    "    trainer_a = L.Trainer(\n",
    "        max_epochs=config.training.max_epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=config.training.early_stopping_patience),\n",
    "            ModelCheckpoint(\n",
    "                dirpath='checkpoints',\n",
    "                filename=f'{experiment_name}_classifier_a_best',\n",
    "                monitor='val_loss'\n",
    "            )\n",
    "        ],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    trainer_a.fit(lit_classifier_a, data_module)\n",
    "    results['classifier_a'] = trainer_a.test(lit_classifier_a, datamodule=data_module)[0]\n",
    "    \n",
    "    # Clasificador B1 (encoder congelado)\n",
    "    print(\"\\nEntrenando Clasificador B1 (encoder congelado)...\")\n",
    "    classifier_b1 = create_encoder_classifier(\n",
    "        autoencoder=autoencoder,\n",
    "        num_classes=data_module.num_classes,\n",
    "        freeze_encoder=True\n",
    "    )\n",
    "    lit_classifier_b1 = LitClassifier(\n",
    "        classifier=classifier_b1,\n",
    "        learning_rate=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "        class_weights=data_module.class_weights\n",
    "    )\n",
    "    \n",
    "    trainer_b1 = L.Trainer(\n",
    "        max_epochs=config.training.max_epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=config.training.early_stopping_patience),\n",
    "            ModelCheckpoint(\n",
    "                dirpath='checkpoints',\n",
    "                filename=f'{experiment_name}_classifier_b1_best',\n",
    "                monitor='val_loss'\n",
    "            )\n",
    "        ],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    trainer_b1.fit(lit_classifier_b1, data_module)\n",
    "    results['classifier_b1'] = trainer_b1.test(lit_classifier_b1, datamodule=data_module)[0]\n",
    "    \n",
    "    # Clasificador B2 (encoder entrenable)\n",
    "    print(\"\\nEntrenando Clasificador B2 (encoder entrenable)...\")\n",
    "    classifier_b2 = create_encoder_classifier(\n",
    "        autoencoder=autoencoder,\n",
    "        num_classes=data_module.num_classes,\n",
    "        freeze_encoder=False\n",
    "    )\n",
    "    lit_classifier_b2 = LitClassifier(\n",
    "        classifier=classifier_b2,\n",
    "        learning_rate=config.training.learning_rate,\n",
    "        weight_decay=config.training.weight_decay,\n",
    "        class_weights=data_module.class_weights\n",
    "    )\n",
    "    \n",
    "    trainer_b2 = L.Trainer(\n",
    "        max_epochs=config.training.max_epochs,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=config.training.early_stopping_patience),\n",
    "            ModelCheckpoint(\n",
    "                dirpath='checkpoints',\n",
    "                filename=f'{experiment_name}_classifier_b2_best',\n",
    "                monitor='val_loss'\n",
    "            )\n",
    "        ],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1\n",
    "    )\n",
    "    \n",
    "    trainer_b2.fit(lit_classifier_b2, data_module)\n",
    "    results['classifier_b2'] = trainer_b2.test(lit_classifier_b2, datamodule=data_module)[0]\n",
    "    \n",
    "    # Cuantización y comparación de modelos\n",
    "    classifiers = {\n",
    "        'classifier_a': lit_classifier_a.classifier,\n",
    "        'classifier_b1': lit_classifier_b1.classifier,\n",
    "        'classifier_b2': lit_classifier_b2.classifier\n",
    "    }\n",
    "    \n",
    "    print(\"\\nRealizando cuantización y comparación de modelos...\")\n",
    "    quantization_results = {}\n",
    "    \n",
    "    for name, model in classifiers.items():\n",
    "        print(f\"\\nProcesando {name}...\")\n",
    "        # Cuantizar modelo\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            model,\n",
    "            {torch.nn.Linear, torch.nn.Conv2d},\n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "        \n",
    "        # Comparar versiones\n",
    "        comparison = compare_model_versions(\n",
    "            original_model=model,\n",
    "            quantized_model=quantized_model,\n",
    "            test_dataloader=data_module.test_dataloader(),\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        quantization_results[name] = comparison\n",
    "        \n",
    "        # Log a wandb\n",
    "        wandb.log({\n",
    "            f\"{name}/original_accuracy\": comparison['original_metrics']['accuracy'],\n",
    "            f\"{name}/quantized_accuracy\": comparison['quantized_metrics']['accuracy'],\n",
    "            f\"{name}/size_reduction\": comparison['size_reduction_ratio'],\n",
    "            f\"{name}/latency_improvement\": comparison['latency_improvement']\n",
    "        })\n",
    "    \n",
    "    # Guardar resultados\n",
    "    final_results = {\n",
    "        'training_results': results,\n",
    "        'quantization_results': quantization_results,\n",
    "        'config': OmegaConf.to_container(config, resolve=True)\n",
    "    }\n",
    "    \n",
    "    save_experiment_results(\n",
    "        results=final_results,\n",
    "        save_dir=Path('results'),\n",
    "        experiment_name=experiment_name\n",
    "    )\n",
    "    \n",
    "    wandb.finish()\n",
    "    return final_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ejecutar experimento con diferentes ratios\n",
    "    ratios = [0.7, 0.9]\n",
    "    all_results = {}\n",
    "    \n",
    "    for ratio in ratios:\n",
    "        print(f\"\\nEjecutando experimento con {ratio*100}% datos sin etiquetas\")\n",
    "        results = train_experiment(ratio)\n",
    "        all_results[f\"ratio_{ratio}\"] = results\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(f\"\\nResultados para ratio {ratio}:\")\n",
    "        for model_name, metrics in results['training_results'].items():\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Test accuracy: {metrics['test_acc']:.4f}\")\n",
    "            print(f\"Test loss: {metrics['test_loss']:.4f}\")\n",
    "            \n",
    "            quant_results = results['quantization_results'][model_name]\n",
    "            print(f\"Size reduction: {quant_results['size_reduction_ratio']*100:.2f}%\")\n",
    "            print(f\"Latency improvement: {quant_results['latency_improvement']*100:.2f}%\")\n",
    "            print(f\"Accuracy impact: {quant_results['accuracy_difference']*100:.2f}%\")\n",
    "\n",
    "    # Guardar resultados globales\n",
    "    import json\n",
    "    with open('results/all_results.json', 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
