{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuración de Weights & Biases Online ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: dnlalvarado19 (dnlalvarado19-instituto-tecnol-gico-de-costa-rica). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b993ab3d598c489eac77e3e14d2f8f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888278356, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\dnlal\\OneDrive\\Documents\\GitHub\\Proyecto3-IA\\wandb\\run-20241121_143029-fti4j2il</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/fti4j2il' target=\"_blank\">test-connection</a></strong> to <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/fti4j2il' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/fti4j2il</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>connection_test</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>connection_test</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test-connection</strong> at: <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/fti4j2il' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/fti4j2il</a><br/> View project at: <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241121_143029-fti4j2il\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Conexión exitosa con wandb\n",
      "✓ Login verificado\n",
      "✓ Logging probado correctamente\n",
      "\n",
      "Weights & Biases está configurado correctamente en modo online\n"
     ]
    }
   ],
   "source": [
    "# === CELDA DE CONFIGURACIÓN WANDB (EJECUTAR PRIMERO) ===\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# Pegar tu API key aquí\n",
    "WANDB_API_KEY = \"619223e73ca0d6bb2a62fe224779121e4c7ebe1a\"  # Reemplaza con tu API key de wandb\n",
    "\n",
    "def setup_wandb_online():\n",
    "    \"\"\"Configura Weights & Biases en modo online\"\"\"\n",
    "    print(\"=== Configuración de Weights & Biases Online ===\")\n",
    "    \n",
    "    # Configurar API key\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    \n",
    "    # Intentar login\n",
    "    try:\n",
    "        wandb.login()\n",
    "        \n",
    "        # Verificar configuración con una prueba\n",
    "        with wandb.init(\n",
    "            project=\"butterfly-classification\",\n",
    "            name=\"test-connection\",\n",
    "            tags=[\"test\"],\n",
    "        ) as run:\n",
    "            wandb.log({\"connection_test\": 1.0})\n",
    "            \n",
    "        print(\"\\n✓ Conexión exitosa con wandb\")\n",
    "        print(\"✓ Login verificado\")\n",
    "        print(\"✓ Logging probado correctamente\")\n",
    "        print(\"\\nWeights & Biases está configurado correctamente en modo online\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error al configurar wandb: {e}\")\n",
    "        print(\"Por favor, verifica tu API key y conexión a internet\")\n",
    "        raise e\n",
    "\n",
    "# Ejecutar configuración\n",
    "setup_wandb_online()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando entorno...\n",
      "Python version: 3.12.4 (tags/v3.12.4:8e8a4ba, Jun  6 2024, 19:30:16) [MSC v.1940 64 bit (AMD64)]\n",
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3070\n",
      "\n",
      "Entorno verificado correctamente ✓\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 0: VERIFICACIÓN DEL ENTORNO ===\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def verify_environment():\n",
    "    print(\"Verificando entorno...\")\n",
    "    \n",
    "    # Verificar Python\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    \n",
    "    # Verificar PyTorch y CUDA\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Verificar estructura del proyecto\n",
    "    required_files = ['models.py', 'utils.py', 'conf/config.yaml']\n",
    "    for file in required_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"Missing required file: {file}\")\n",
    "    \n",
    "    # Verificar dataset\n",
    "    if not os.path.exists('Butterfly-dataset'):\n",
    "        raise FileNotFoundError(\"Dataset directory not found\")\n",
    "        \n",
    "    print(\"\\nEntorno verificado correctamente ✓\")\n",
    "\n",
    "verify_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dependencias básicas importadas correctamente\n",
      "✓ Módulos locales importados correctamente\n",
      "\n",
      "Configuración del dispositivo:\n",
      "- Usando: cuda\n",
      "- CUDA disponible: True\n",
      "- GPU: NVIDIA GeForce RTX 3070\n",
      "- Memoria GPU total: 8.59 GB\n",
      "\n",
      "Verificación de rutas:\n",
      "✓ Modelos: models.py\n",
      "✓ Utilidades: utils.py\n",
      "✓ Configuración: conf/config.yaml\n",
      "✓ Dataset: Butterfly-dataset\n"
     ]
    }
   ],
   "source": [
    "# ============= CELDA 1: IMPORTS Y CONFIGURACIÓN INICIAL =============\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Asegurar que los módulos locales están en el path\n",
    "project_root = Path().absolute()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Imports básicos\n",
    "try:\n",
    "    import torch\n",
    "    import lightning as L\n",
    "    import hydra\n",
    "    import wandb\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from omegaconf import DictConfig, OmegaConf\n",
    "    from datetime import datetime\n",
    "    print(\"✓ Dependencias básicas importadas correctamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importando dependencias básicas: {e}\")\n",
    "    print(\"Asegúrate de haber instalado todas las dependencias del requirements.txt\")\n",
    "    raise\n",
    "\n",
    "# Importar módulos locales\n",
    "try:\n",
    "    from models import ButterflyAutoencoder, ButterflyClassifier, ButterflyDataModule\n",
    "    from utils import (clean_gpu_memory, verify_dataset_structure, plot_confusion_matrix,\n",
    "                      measure_inference_performance, plot_training_curves,\n",
    "                      compare_model_variants, save_experiment_config)\n",
    "    print(\"✓ Módulos locales importados correctamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importando módulos locales: {e}\")\n",
    "    print(\"Verifica que estás ejecutando el notebook desde el directorio raíz del proyecto\")\n",
    "    raise\n",
    "\n",
    "# Configurar warnings y reproducibilidad\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configurar estilo de visualización\n",
    "plt.style.use('default')  # Usar estilo default primero\n",
    "sns.set_style(\"whitegrid\")  # Aplicar estilo de seaborn\n",
    "sns.set_context(\"notebook\")  # Ajustar contexto para notebook\n",
    "\n",
    "# Verificar GPU y mostrar información del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nConfiguración del dispositivo:\")\n",
    "print(f\"- Usando: {device}\")\n",
    "print(f\"- CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"- GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"- Memoria GPU total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Verificar rutas críticas\n",
    "print(\"\\nVerificación de rutas:\")\n",
    "critical_paths = {\n",
    "    'Modelos': 'models.py',\n",
    "    'Utilidades': 'utils.py',\n",
    "    'Configuración': 'conf/config.yaml',\n",
    "    'Dataset': 'Butterfly-dataset'\n",
    "}\n",
    "\n",
    "for name, path in critical_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✓ {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"❌ {name} no encontrado: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CELDA 2: DEFINICIÓN DE CONFIGURACIONES =============\n",
    "\n",
    "# Configuración base del experimento\n",
    "BASE_CONFIG = {\n",
    "    'seed': 42,\n",
    "    'data_dir': 'Butterfly-dataset',\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 4,\n",
    "    'max_epochs': 100,\n",
    "    'early_stopping_patience': 10,\n",
    "}\n",
    "\n",
    "# Configuración para experimento 70/30\n",
    "CONFIG_70_30 = {\n",
    "    'name': 'exp1_70_30',\n",
    "    'description': 'Experiment with 70% unlabeled and 30% labeled data',\n",
    "    'labeled_ratio': 0.3,\n",
    "    'autoencoder': {\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 1e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'noise_factor': 0.1,\n",
    "    },\n",
    "    'classifier_variants': [\n",
    "        {\n",
    "            'name': 'from_scratch',\n",
    "            'description': 'Classifier trained from scratch',\n",
    "            'use_pretrained': False,\n",
    "            'freeze_encoder': False,\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-5,\n",
    "        },\n",
    "        {\n",
    "            'name': 'pretrained_frozen',\n",
    "            'description': 'Classifier with frozen pretrained encoder',\n",
    "            'use_pretrained': True,\n",
    "            'freeze_encoder': True,\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-5,\n",
    "        },\n",
    "        {\n",
    "            'name': 'pretrained_unfrozen',\n",
    "            'description': 'Classifier with unfrozen pretrained encoder',\n",
    "            'use_pretrained': True,\n",
    "            'freeze_encoder': False,\n",
    "            'learning_rate': 1e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Configuración para experimento 90/10\n",
    "CONFIG_90_10 = {\n",
    "    'name': 'exp1_90_10',\n",
    "    'description': 'Experiment with 90% unlabeled and 10% labeled data',\n",
    "    'labeled_ratio': 0.1,\n",
    "    'autoencoder': {\n",
    "        'epochs': 75,\n",
    "        'learning_rate': 1e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'noise_factor': 0.1,\n",
    "    },\n",
    "    'classifier_variants': CONFIG_70_30['classifier_variants']  # Mismas variantes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CELDA 3: FUNCIONES DE ENTRENAMIENTO =============\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def setup_wandb(config: dict, experiment_name: str, variant_name: str = None):\n",
    "    \"\"\"Configura Weights & Biases para el experimento\"\"\"\n",
    "    try:\n",
    "        with hydra.initialize_config_module(config_module=\"conf\"):\n",
    "            cfg = hydra.compose(config_name=\"config\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load hydra config: {e}\")\n",
    "        # Configuración fallback\n",
    "        cfg = {\n",
    "            'wandb': {\n",
    "                'project': \"butterfly-classification\",\n",
    "                'entity': None,\n",
    "                'tags': [\"transfer-learning\", \"butterflies\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    run_name = f\"{experiment_name}_{variant_name}\" if variant_name else experiment_name\n",
    "    try:\n",
    "        wandb.init(\n",
    "            project=cfg['wandb']['project'],\n",
    "            entity=cfg['wandb']['entity'],\n",
    "            name=run_name,\n",
    "            config={**config, **cfg},\n",
    "            tags=cfg['wandb']['tags'] + [experiment_name],\n",
    "            mode=\"online\"  # o usa el valor de cfg si está disponible\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not initialize wandb: {e}\")\n",
    "        print(\"Continuing without wandb logging...\")\n",
    "\n",
    "def train_autoencoder(config: dict, datamodule: ButterflyDataModule) -> ButterflyAutoencoder:\n",
    "    \"\"\"Entrena el autoencoder\"\"\"\n",
    "    print(f\"\\nTraining Autoencoder for {config['name']}\")\n",
    "    \n",
    "    setup_wandb(config, f\"autoencoder_{config['name']}\")\n",
    "    \n",
    "    model = ButterflyAutoencoder(\n",
    "        learning_rate=config['autoencoder']['learning_rate'],\n",
    "        weight_decay=config['autoencoder']['weight_decay']\n",
    "    )\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['autoencoder']['epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=BASE_CONFIG['early_stopping_patience'],\n",
    "                mode='min'\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, \n",
    "               train_dataloaders=datamodule.train_dataloader(labeled=False),\n",
    "               val_dataloaders=datamodule.val_dataloader())\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model\n",
    "\n",
    "def train_classifier(config: dict,\n",
    "                    variant_config: dict,\n",
    "                    datamodule: ButterflyDataModule,\n",
    "                    pretrained_encoder: torch.nn.Module = None) -> ButterflyClassifier:\n",
    "    \"\"\"Entrena una variante del clasificador\"\"\"\n",
    "    print(f\"\\nTraining Classifier: {variant_config['name']}\")\n",
    "    \n",
    "    setup_wandb(config, f\"classifier_{config['name']}\", variant_config['name'])\n",
    "    \n",
    "    model = ButterflyClassifier(\n",
    "        num_classes=20,\n",
    "        learning_rate=variant_config['learning_rate'],\n",
    "        weight_decay=variant_config['weight_decay'],\n",
    "        pretrained_encoder=pretrained_encoder if variant_config['use_pretrained'] else None,\n",
    "        freeze_encoder=variant_config['freeze_encoder']\n",
    "    )\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=BASE_CONFIG['max_epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=BASE_CONFIG['early_stopping_patience'],\n",
    "                mode='min'\n",
    "            ),\n",
    "            ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model,\n",
    "               train_dataloaders=datamodule.train_dataloader(labeled=True),\n",
    "               val_dataloaders=datamodule.val_dataloader())\n",
    "    \n",
    "    # Evaluación\n",
    "    test_results = trainer.test(model, datamodule.test_dataloader())[0]\n",
    "    wandb.log({\"test_results\": test_results})\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.test_dataloader():\n",
    "            x, y = batch\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        datamodule.get_class_names(),\n",
    "        title=f\"Confusion Matrix - {variant_config['name']}\"\n",
    "    )\n",
    "    \n",
    "    # Análisis de rendimiento\n",
    "    perf_metrics = measure_inference_performance(model, datamodule.test_dataloader())\n",
    "    wandb.log(perf_metrics)\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model, test_results, perf_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============= CELDA 4: FUNCIÓN PRINCIPAL DE EXPERIMENTO =============\n",
    "\n",
    "def run_experiment(config: dict):\n",
    "    \"\"\"Ejecuta un experimento completo\"\"\"\n",
    "    print(f\"\\nStarting experiment: {config['name']}\")\n",
    "    print(f\"Description: {config['description']}\")\n",
    "    \n",
    "    # Crear directorio para resultados\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path(f\"outputs/{config['name']}_{timestamp}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Verificar dataset\n",
    "    if not verify_dataset_structure(BASE_CONFIG['data_dir']):\n",
    "        raise ValueError(\"Dataset structure is invalid\")\n",
    "    \n",
    "    # Inicializar DataModule\n",
    "    datamodule = ButterflyDataModule(\n",
    "        data_dir=BASE_CONFIG['data_dir'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        num_workers=BASE_CONFIG['num_workers'],\n",
    "        labeled_ratio=config['labeled_ratio']\n",
    "    )\n",
    "    datamodule.setup()\n",
    "    \n",
    "    # Entrenar autoencoder\n",
    "    autoencoder = train_autoencoder(config, datamodule)\n",
    "    clean_gpu_memory()\n",
    "    \n",
    "    # Entrenar variantes del clasificador\n",
    "    results = []\n",
    "    for variant_config in config['classifier_variants']:\n",
    "        try:\n",
    "            model, test_results, perf_metrics = train_classifier(\n",
    "                config,\n",
    "                variant_config,\n",
    "                datamodule,\n",
    "                pretrained_encoder=autoencoder.encoder if variant_config['use_pretrained'] else None\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'variant': variant_config['name'],\n",
    "                'test_accuracy': test_results['test_acc'],\n",
    "                'test_f1': test_results['test_f1'],\n",
    "                **perf_metrics\n",
    "            })\n",
    "            \n",
    "            clean_gpu_memory()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {variant_config['name']}: {e}\")\n",
    "    \n",
    "    # Comparar resultados\n",
    "    compare_model_variants(\n",
    "        results,\n",
    "        metrics=['test_accuracy', 'test_f1', 'avg_latency', 'model_size_mb'],\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Guardar configuración\n",
    "    save_experiment_config(config, output_dir)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Starting 70/30 experiment...\n",
      "\n",
      "Starting experiment: exp1_70_30\n",
      "Description: Experiment with 70% unlabeled and 30% labeled data\n",
      "\n",
      "Training Autoencoder for exp1_70_30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\dnlal\\OneDrive\\Documents\\GitHub\\Proyecto3-IA\\wandb\\run-20241121_151021-l56r1krv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/l56r1krv' target=\"_blank\">autoencoder_exp1_70_30</a></strong> to <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/l56r1krv' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/l56r1krv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type        | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | encoder | UNetEncoder | 4.8 M  | train\n",
      "1 | decoder | UNetDecoder | 3.0 M  | train\n",
      "------------------------------------------------\n",
      "7.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.8 M     Total params\n",
      "31.338    Total estimated model params size (MB)\n",
      "67        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9306fe20a119442ea46fa99fd464517e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in execution: randn_like(): argument 'input' (position 1) must be Tensor, not list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dnlal\\AppData\\Local\\Temp\\ipykernel_59640\\2668822929.py\", line 17, in main\n",
      "    results_70_30 = run_experiment(CONFIG_70_30)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dnlal\\AppData\\Local\\Temp\\ipykernel_59640\\3596518683.py\", line 27, in run_experiment\n",
      "    autoencoder = train_autoencoder(config, datamodule)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dnlal\\AppData\\Local\\Temp\\ipykernel_59640\\484631367.py\", line 63, in train_autoencoder\n",
      "    trainer.fit(model,\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 538, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 574, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 981, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1023, in _run_stage\n",
      "    self._run_sanity_check()\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py\", line 1052, in _run_sanity_check\n",
      "    val_loop.run()\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py\", line 178, in _decorator\n",
      "    return loop_run(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py\", line 135, in run\n",
      "    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py\", line 396, in _evaluation_step\n",
      "    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py\", line 319, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py\", line 411, in validation_step\n",
      "    return self.lightning_module.validation_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\OneDrive\\Documents\\GitHub\\Proyecto3-IA\\models.py\", line 113, in validation_step\n",
      "    f\"{phase}/original\": wandb.Image(x[0].cpu()),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dnlal\\OneDrive\\Documents\\GitHub\\Proyecto3-IA\\models.py\", line 102, in _shared_step\n",
      "    noisy_x = x + torch.randn_like(x) * 0.1\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: randn_like(): argument 'input' (position 1) must be Tensor, not list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autoencoder_exp1_70_30</strong> at: <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/l56r1krv' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification/runs/l56r1krv</a><br/> View project at: <a href='https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification' target=\"_blank\">https://wandb.ai/dnlalvarado19-instituto-tecnol-gico-de-costa-rica/butterfly-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241121_151021-l56r1krv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============= CELDA 5: EJECUCIÓN DE EXPERIMENTOS =============\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal de ejecución\"\"\"\n",
    "    try:\n",
    "        # Verificar GPU y configurar reproducibilidad\n",
    "        print(f\"Using device: {device}\")\n",
    "        torch.manual_seed(BASE_CONFIG['seed'])\n",
    "        \n",
    "        # Configurar wandb\n",
    "        if os.environ.get(\"WANDB_API_KEY\") is None:\n",
    "            print(\"WANDB: Running in offline mode\")\n",
    "            os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "        \n",
    "        # Ejecutar experimento 70/30\n",
    "        print(\"\\nStarting 70/30 experiment...\")\n",
    "        results_70_30 = run_experiment(CONFIG_70_30)\n",
    "        \n",
    "        # Preguntar si continuar con 90/10\n",
    "        response = input(\"\\nContinue with 90/10 experiment? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            print(\"\\nStarting 90/10 experiment...\")\n",
    "            results_90_10 = run_experiment(CONFIG_90_10)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExperiment interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clean_gpu_memory()\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CELDA 6 (OPCIONAL): ANÁLISIS DE RESULTADOS =============\n",
    "# Esta celda se puede ejecutar después de completar los experimentos\n",
    "\n",
    "def analyze_results():\n",
    "    \"\"\"Analiza y compara resultados de ambos experimentos\"\"\"\n",
    "    results_dir = Path(\"outputs\")\n",
    "    \n",
    "    # Encontrar los directorios más recientes para cada experimento\n",
    "    exp_70_30_dir = sorted(results_dir.glob(\"exp1_70_30_*\"))[-1]\n",
    "    exp_90_10_dir = sorted(results_dir.glob(\"exp1_90_10_*\"))[-1]\n",
    "    \n",
    "    # Cargar resultados\n",
    "    results_70_30 = pd.read_csv(exp_70_30_dir / \"model_comparison.csv\")\n",
    "    results_90_10 = pd.read_csv(exp_90_10_dir / \"model_comparison.csv\")\n",
    "    \n",
    "    # Comparar resultados\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    metrics = ['test_accuracy', 'test_f1']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 1, i)\n",
    "        \n",
    "        x = np.arange(len(results_70_30))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, results_70_30[metric], width, label='70/30 split')\n",
    "        plt.bar(x + width/2, results_90_10[metric], width, label='90/10 split')\n",
    "        \n",
    "        plt.xlabel('Model Variant')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'Comparison of {metric}')\n",
    "        plt.xticks(x, results_70_30['variant'], rotation=45)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Para ejecutar el análisis:\n",
    "# analyze_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
