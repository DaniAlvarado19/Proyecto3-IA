{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configuración de Weights & Biases Online ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbbbe5cad974fca9f6061bdf683fc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888278356, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Error al configurar wandb: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.\n",
      "Por favor, verifica tu API key y conexión a internet\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Ejecutar configuración\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43msetup_wandb_online\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m, in \u001b[0;36msetup_wandb_online\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m❌ Error al configurar wandb: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPor favor, verifica tu API key y conexión a internet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36msetup_wandb_online\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlogin()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Verificar configuración con una prueba\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbutterfly-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest-connection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m     25\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection_test\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1.0\u001b[39m})\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Conexión exitosa con wandb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1270\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[0;32m   1266\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[1;32m-> 1270\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\analytics\\sentry.py:161\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[1;34m(self, exc)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1256\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, resume_from, settings)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     wi \u001b[38;5;241m=\u001b[39m _WandbInit()\n\u001b[0;32m   1255\u001b[0m     wi\u001b[38;5;241m.\u001b[39msetup(kwargs)\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:847\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    845\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m--> 847\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mCommError\u001b[0m: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`."
     ]
    }
   ],
   "source": [
    "# === CELDA DE CONFIGURACIÓN WANDB (EJECUTAR PRIMERO) ===\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# Pegar tu API key aquí\n",
    "WANDB_API_KEY = \"619223e73ca0d6bb2a62fe224779121e4c7ebe1a\"  # Reemplaza con tu API key de wandb\n",
    "\n",
    "def setup_wandb_online():\n",
    "    \"\"\"Configura Weights & Biases en modo online\"\"\"\n",
    "    print(\"=== Configuración de Weights & Biases Online ===\")\n",
    "    \n",
    "    # Configurar API key\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    \n",
    "    # Intentar login\n",
    "    try:\n",
    "        wandb.login()\n",
    "        \n",
    "        # Verificar configuración con una prueba\n",
    "        with wandb.init(\n",
    "            project=\"butterfly-classification\",\n",
    "            name=\"test-connection\",\n",
    "            tags=[\"test\"],\n",
    "        ) as run:\n",
    "            wandb.log({\"connection_test\": 1.0})\n",
    "            \n",
    "        print(\"\\n✓ Conexión exitosa con wandb\")\n",
    "        print(\"✓ Login verificado\")\n",
    "        print(\"✓ Logging probado correctamente\")\n",
    "        print(\"\\nWeights & Biases está configurado correctamente en modo online\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error al configurar wandb: {e}\")\n",
    "        print(\"Por favor, verifica tu API key y conexión a internet\")\n",
    "        raise e\n",
    "\n",
    "# Ejecutar configuración\n",
    "setup_wandb_online()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando entorno...\n",
      "Python version: 3.12.4 (tags/v3.12.4:8e8a4ba, Jun  6 2024, 19:30:16) [MSC v.1940 64 bit (AMD64)]\n",
      "PyTorch version: 2.5.1+cu118\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3070\n",
      "\n",
      "Entorno verificado correctamente ✓\n"
     ]
    }
   ],
   "source": [
    "# === CELDA 0: VERIFICACIÓN DEL ENTORNO ===\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def verify_environment():\n",
    "    print(\"Verificando entorno...\")\n",
    "    \n",
    "    # Verificar Python\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    \n",
    "    # Verificar PyTorch y CUDA\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Verificar estructura del proyecto\n",
    "    required_files = ['models.py', 'utils.py', 'conf/config.yaml']\n",
    "    for file in required_files:\n",
    "        if not os.path.exists(file):\n",
    "            raise FileNotFoundError(f\"Missing required file: {file}\")\n",
    "    \n",
    "    # Verificar dataset\n",
    "    if not os.path.exists('Butterfly-dataset'):\n",
    "        raise FileNotFoundError(\"Dataset directory not found\")\n",
    "        \n",
    "    print(\"\\nEntorno verificado correctamente ✓\")\n",
    "\n",
    "verify_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\style\\core.py:137\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:870\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[1;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[0;32m    869\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 870\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:847\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    846\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[1;32m--> 847\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Verificar GPU\u001b[39;00m\n\u001b[0;32m     29\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dnlal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\style\\core.py:139\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# ============= CELDA 1: IMPORTS Y CONFIGURACIÓN INICIAL =============\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import lightning as L\n",
    "import hydra\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Importar módulos locales\n",
    "from models import ButterflyAutoencoder, ButterflyClassifier, ButterflyDataModule\n",
    "from utils import (clean_gpu_memory, verify_dataset_structure, plot_confusion_matrix,\n",
    "                  measure_inference_performance, plot_training_curves,\n",
    "                  compare_model_variants, save_experiment_config)\n",
    "\n",
    "# Configurar warnings y reproducibilidad\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Verificar GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= CELDA 2: DEFINICIÓN DE CONFIGURACIONES =============\n",
    "\n",
    "# Configuración base del experimento\n",
    "BASE_CONFIG = {\n",
    "    'seed': 42,\n",
    "    'data_dir': 'Butterfly-dataset',\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 4,\n",
    "    'max_epochs': 100,\n",
    "    'early_stopping_patience': 10,\n",
    "}\n",
    "\n",
    "# Configuración para experimento 70/30\n",
    "CONFIG_70_30 = {\n",
    "    'name': 'exp1_70_30',\n",
    "    'description': 'Experiment with 70% unlabeled and 30% labeled data',\n",
    "    'labeled_ratio': 0.3,\n",
    "    'autoencoder': {\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 1e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'noise_factor': 0.1,\n",
    "    },\n",
    "    'classifier_variants': [\n",
    "        {\n",
    "            'name': 'from_scratch',\n",
    "            'description': 'Classifier trained from scratch',\n",
    "            'use_pretrained': False,\n",
    "            'freeze_encoder': False,\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-5,\n",
    "        },\n",
    "        {\n",
    "            'name': 'pretrained_frozen',\n",
    "            'description': 'Classifier with frozen pretrained encoder',\n",
    "            'use_pretrained': True,\n",
    "            'freeze_encoder': True,\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-5,\n",
    "        },\n",
    "        {\n",
    "            'name': 'pretrained_unfrozen',\n",
    "            'description': 'Classifier with unfrozen pretrained encoder',\n",
    "            'use_pretrained': True,\n",
    "            'freeze_encoder': False,\n",
    "            'learning_rate': 1e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Configuración para experimento 90/10\n",
    "CONFIG_90_10 = {\n",
    "    'name': 'exp1_90_10',\n",
    "    'description': 'Experiment with 90% unlabeled and 10% labeled data',\n",
    "    'labeled_ratio': 0.1,\n",
    "    'autoencoder': {\n",
    "        'epochs': 75,\n",
    "        'learning_rate': 1e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'noise_factor': 0.1,\n",
    "    },\n",
    "    'classifier_variants': CONFIG_70_30['classifier_variants']  # Mismas variantes\n",
    "}\n",
    "\n",
    "# ============= CELDA 3: FUNCIONES DE ENTRENAMIENTO =============\n",
    "\n",
    "def setup_wandb(config: dict, experiment_name: str, variant_name: str = None):\n",
    "    \"\"\"Configura Weights & Biases para el experimento\"\"\"\n",
    "    with hydra.initialize(version_base=None, config_path=\"conf\"):\n",
    "        cfg = hydra.compose(config_name=\"config\")\n",
    "    \n",
    "    run_name = f\"{experiment_name}_{variant_name}\" if variant_name else experiment_name\n",
    "    try:\n",
    "        wandb.init(\n",
    "            project=cfg.wandb.project,\n",
    "            entity=cfg.wandb.entity,\n",
    "            name=run_name,\n",
    "            config={**config, **OmegaConf.to_container(cfg, resolve=True)},\n",
    "            tags=cfg.wandb.tags + [experiment_name],\n",
    "            mode=cfg.wandb.mode\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not initialize wandb: {e}\")\n",
    "        os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "def train_autoencoder(config: dict, datamodule: ButterflyDataModule) -> ButterflyAutoencoder:\n",
    "    \"\"\"Entrena el autoencoder\"\"\"\n",
    "    print(f\"\\nTraining Autoencoder for {config['name']}\")\n",
    "    \n",
    "    setup_wandb(config, f\"autoencoder_{config['name']}\")\n",
    "    \n",
    "    model = ButterflyAutoencoder(\n",
    "        learning_rate=config['autoencoder']['learning_rate'],\n",
    "        weight_decay=config['autoencoder']['weight_decay']\n",
    "    )\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config['autoencoder']['epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            L.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=BASE_CONFIG['early_stopping_patience'],\n",
    "                mode='min'\n",
    "            ),\n",
    "            L.callbacks.ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model, \n",
    "               train_dataloaders=datamodule.train_dataloader(labeled=False),\n",
    "               val_dataloaders=datamodule.val_dataloader())\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model\n",
    "\n",
    "def train_classifier(config: dict,\n",
    "                    variant_config: dict,\n",
    "                    datamodule: ButterflyDataModule,\n",
    "                    pretrained_encoder: torch.nn.Module = None) -> ButterflyClassifier:\n",
    "    \"\"\"Entrena una variante del clasificador\"\"\"\n",
    "    print(f\"\\nTraining Classifier: {variant_config['name']}\")\n",
    "    \n",
    "    setup_wandb(config, f\"classifier_{config['name']}\", variant_config['name'])\n",
    "    \n",
    "    model = ButterflyClassifier(\n",
    "        num_classes=20,\n",
    "        learning_rate=variant_config['learning_rate'],\n",
    "        weight_decay=variant_config['weight_decay'],\n",
    "        pretrained_encoder=pretrained_encoder if variant_config['use_pretrained'] else None,\n",
    "        freeze_encoder=variant_config['freeze_encoder']\n",
    "    )\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=BASE_CONFIG['max_epochs'],\n",
    "        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "        devices=1,\n",
    "        callbacks=[\n",
    "            L.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=BASE_CONFIG['early_stopping_patience'],\n",
    "                mode='min'\n",
    "            ),\n",
    "            L.callbacks.ModelCheckpoint(\n",
    "                monitor='val_loss',\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model,\n",
    "               train_dataloaders=datamodule.train_dataloader(labeled=True),\n",
    "               val_dataloaders=datamodule.val_dataloader())\n",
    "    \n",
    "    # Evaluación\n",
    "    test_results = trainer.test(model, datamodule.test_dataloader())[0]\n",
    "    wandb.log({\"test_results\": test_results})\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.test_dataloader():\n",
    "            x, y = batch\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        datamodule.get_class_names(),\n",
    "        title=f\"Confusion Matrix - {variant_config['name']}\"\n",
    "    )\n",
    "    \n",
    "    # Análisis de rendimiento\n",
    "    perf_metrics = measure_inference_performance(model, datamodule.test_dataloader())\n",
    "    wandb.log(perf_metrics)\n",
    "    \n",
    "    wandb.finish()\n",
    "    return model, test_results, perf_metrics\n",
    "\n",
    "# ============= CELDA 4: FUNCIÓN PRINCIPAL DE EXPERIMENTO =============\n",
    "\n",
    "def run_experiment(config: dict):\n",
    "    \"\"\"Ejecuta un experimento completo\"\"\"\n",
    "    print(f\"\\nStarting experiment: {config['name']}\")\n",
    "    print(f\"Description: {config['description']}\")\n",
    "    \n",
    "    # Crear directorio para resultados\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = Path(f\"outputs/{config['name']}_{timestamp}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Verificar dataset\n",
    "    if not verify_dataset_structure(BASE_CONFIG['data_dir']):\n",
    "        raise ValueError(\"Dataset structure is invalid\")\n",
    "    \n",
    "    # Inicializar DataModule\n",
    "    datamodule = ButterflyDataModule(\n",
    "        data_dir=BASE_CONFIG['data_dir'],\n",
    "        batch_size=BASE_CONFIG['batch_size'],\n",
    "        num_workers=BASE_CONFIG['num_workers'],\n",
    "        labeled_ratio=config['labeled_ratio']\n",
    "    )\n",
    "    datamodule.setup()\n",
    "    \n",
    "    # Entrenar autoencoder\n",
    "    autoencoder = train_autoencoder(config, datamodule)\n",
    "    clean_gpu_memory()\n",
    "    \n",
    "    # Entrenar variantes del clasificador\n",
    "    results = []\n",
    "    for variant_config in config['classifier_variants']:\n",
    "        try:\n",
    "            model, test_results, perf_metrics = train_classifier(\n",
    "                config,\n",
    "                variant_config,\n",
    "                datamodule,\n",
    "                pretrained_encoder=autoencoder.encoder if variant_config['use_pretrained'] else None\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'variant': variant_config['name'],\n",
    "                'test_accuracy': test_results['test_acc'],\n",
    "                'test_f1': test_results['test_f1'],\n",
    "                **perf_metrics\n",
    "            })\n",
    "            \n",
    "            clean_gpu_memory()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error training {variant_config['name']}: {e}\")\n",
    "    \n",
    "    # Comparar resultados\n",
    "    compare_model_variants(\n",
    "        results,\n",
    "        metrics=['test_accuracy', 'test_f1', 'avg_latency', 'model_size_mb'],\n",
    "        save_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Guardar configuración\n",
    "    save_experiment_config(config, output_dir)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ============= CELDA 5: EJECUCIÓN DE EXPERIMENTOS =============\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal de ejecución\"\"\"\n",
    "    try:\n",
    "        # Verificar GPU y configurar reproducibilidad\n",
    "        print(f\"Using device: {device}\")\n",
    "        torch.manual_seed(BASE_CONFIG['seed'])\n",
    "        \n",
    "        # Configurar wandb\n",
    "        if os.environ.get(\"WANDB_API_KEY\") is None:\n",
    "            print(\"WANDB: Running in offline mode\")\n",
    "            os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "        \n",
    "        # Ejecutar experimento 70/30\n",
    "        print(\"\\nStarting 70/30 experiment...\")\n",
    "        results_70_30 = run_experiment(CONFIG_70_30)\n",
    "        \n",
    "        # Preguntar si continuar con 90/10\n",
    "        response = input(\"\\nContinue with 90/10 experiment? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            print(\"\\nStarting 90/10 experiment...\")\n",
    "            results_90_10 = run_experiment(CONFIG_90_10)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nExperiment interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError in execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        clean_gpu_memory()\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ============= CELDA 6 (OPCIONAL): ANÁLISIS DE RESULTADOS =============\n",
    "# Esta celda se puede ejecutar después de completar los experimentos\n",
    "\n",
    "def analyze_results():\n",
    "    \"\"\"Analiza y compara resultados de ambos experimentos\"\"\"\n",
    "    results_dir = Path(\"outputs\")\n",
    "    \n",
    "    # Encontrar los directorios más recientes para cada experimento\n",
    "    exp_70_30_dir = sorted(results_dir.glob(\"exp1_70_30_*\"))[-1]\n",
    "    exp_90_10_dir = sorted(results_dir.glob(\"exp1_90_10_*\"))[-1]\n",
    "    \n",
    "    # Cargar resultados\n",
    "    results_70_30 = pd.read_csv(exp_70_30_dir / \"model_comparison.csv\")\n",
    "    results_90_10 = pd.read_csv(exp_90_10_dir / \"model_comparison.csv\")\n",
    "    \n",
    "    # Comparar resultados\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    metrics = ['test_accuracy', 'test_f1']\n",
    "    for i, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 1, i)\n",
    "        \n",
    "        x = np.arange(len(results_70_30))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, results_70_30[metric], width, label='70/30 split')\n",
    "        plt.bar(x + width/2, results_90_10[metric], width, label='90/10 split')\n",
    "        \n",
    "        plt.xlabel('Model Variant')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'Comparison of {metric}')\n",
    "        plt.xticks(x, results_70_30['variant'], rotation=45)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Para ejecutar el análisis:\n",
    "# analyze_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
